<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="hive," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="由于最近项目需要和大数据对接，需要了解一下数仓的基本知识，所以记录一下hive的基础原理和使用 hive简介 Hive是一种用类SQL语句来协助读写、管理那些存储在分布式存储系统上大数据集的数据仓库软件  hive的特点:  通过类SQL来分析大数据，而避免了写MapReduce程序来分析数据，这样使得分析数据更容易 数据是存储在HDFS上的，Hive本身并不提供数据的存储功能 Hive是将数据映">
<meta name="keywords" content="hive">
<meta property="og:type" content="article">
<meta property="og:title" content="hive基本使用">
<meta property="og:url" content="http://yoursite.com/2019/03/08/hive基本使用/index.html">
<meta property="og:site_name" content="Do Or Die">
<meta property="og:description" content="由于最近项目需要和大数据对接，需要了解一下数仓的基本知识，所以记录一下hive的基础原理和使用 hive简介 Hive是一种用类SQL语句来协助读写、管理那些存储在分布式存储系统上大数据集的数据仓库软件  hive的特点:  通过类SQL来分析大数据，而避免了写MapReduce程序来分析数据，这样使得分析数据更容易 数据是存储在HDFS上的，Hive本身并不提供数据的存储功能 Hive是将数据映">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/images/bigdata/hive-arch.jpg">
<meta property="og:image" content="http://yoursite.com/images/bigdata/hive-buckets.jpg">
<meta property="og:image" content="http://yoursite.com/images/bigdata/mapreduce-principle.jpg">
<meta property="og:image" content="http://yoursite.com/images/bigdata/mapreduce.jpg">
<meta property="og:image" content="http://yoursite.com/images/bigdata/map-shuffle.jpg">
<meta property="og:image" content="http://yoursite.com/images/bigdata/reduce-shuffle.jpg">
<meta property="og:updated_time" content="2019-03-11T03:30:38.539Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="hive基本使用">
<meta name="twitter:description" content="由于最近项目需要和大数据对接，需要了解一下数仓的基本知识，所以记录一下hive的基础原理和使用 hive简介 Hive是一种用类SQL语句来协助读写、管理那些存储在分布式存储系统上大数据集的数据仓库软件  hive的特点:  通过类SQL来分析大数据，而避免了写MapReduce程序来分析数据，这样使得分析数据更容易 数据是存储在HDFS上的，Hive本身并不提供数据的存储功能 Hive是将数据映">
<meta name="twitter:image" content="http://yoursite.com/images/bigdata/hive-arch.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.2',
    sidebar: {"position":"left","display":"always","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/03/08/hive基本使用/"/>





  <title>hive基本使用 | Do Or Die</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Do Or Die</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/hive基本使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leo Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Do Or Die">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">hive基本使用</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T17:48:51+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>由于最近项目需要和大数据对接，需要了解一下数仓的基本知识，所以记录一下hive的基础原理和使用</p>
<h3 id="hive简介"><a href="#hive简介" class="headerlink" title="hive简介"></a>hive简介</h3><blockquote>
<p>Hive是一种用类SQL语句来协助读写、管理那些存储在分布式存储系统上大数据集的数据仓库软件</p>
</blockquote>
<p>hive的特点:</p>
<ul>
<li>通过类SQL来分析大数据，而避免了写MapReduce程序来分析数据，这样使得分析数据更容易</li>
<li>数据是存储在HDFS上的，Hive本身并不提供数据的存储功能</li>
<li>Hive是将数据映射成数据库和一张张的表，库和表的元数据信息一般存在关系型数据库上（比如MySQL）</li>
<li>数据存储方面：它能够存储很大的数据集，并且对数据完整性、格式要求并不严格</li>
<li>数据处理方面：因为Hive语句最终会生成MapReduce任务去计算，所以不适用于实时计算的场景，它适用于离线分析</li>
</ul>
<h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p><img src="/images/bigdata/hive-arch.jpg" alt=""></p>
<h4 id="驱动引擎"><a href="#驱动引擎" class="headerlink" title="驱动引擎"></a>驱动引擎</h4><p>Hive的核心是驱动引擎，驱动引擎由四部分组成：</p>
<ul>
<li>解释器：解释器的作用是将HiveSQL语句转换为语法树（AST）</li>
<li>编译器：编译器是将语法树编译为逻辑执行计划</li>
<li>优化器：优化器是对逻辑执行计划进行优化</li>
<li>执行器：执行器是调用底层的运行框架执行逻辑执行计划</li>
</ul>
<h4 id="底层存储和执行流程"><a href="#底层存储和执行流程" class="headerlink" title="底层存储和执行流程"></a>底层存储和执行流程</h4><p>Hive的数据是存储在HDFS上的。Hive中的库和表可以看作是对HDFS上数据做的一个映射。所以Hive必须是运行在一个Hadoop集群上的</p>
<p>Hive中的执行器，是将最终要执行的MapReduce程序放到YARN上以一系列Job的方式去执行</p>
<h4 id="Hive元数据的存储结构"><a href="#Hive元数据的存储结构" class="headerlink" title="Hive元数据的存储结构"></a>Hive元数据的存储结构</h4><p>Hive的元数据是一般是存储在MySQL这种关系型数据库上的，Hive和MySQL之间通过MetaStore服务交互</p>
<table>
<thead>
<tr>
<th>元数据项</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Owner</td>
<td>库、表的所属者</td>
</tr>
<tr>
<td>LastAccessTime</td>
<td>最后修改时间</td>
</tr>
<tr>
<td>Table Type</td>
<td>表类型（内部表、外部表）</td>
</tr>
<tr>
<td>CreateTime</td>
<td>创建时间</td>
</tr>
<tr>
<td>Location</td>
<td>存储位置</td>
</tr>
</tbody>
</table>
<h4 id="Hive客户端"><a href="#Hive客户端" class="headerlink" title="Hive客户端"></a>Hive客户端</h4><p>Hive的客户端种类:</p>
<ul>
<li>cli命令行客户端：采用交互窗口，用hive命令行和Hive进行通信。</li>
<li>HiveServer2客户端：用Thrift协议进行通信，Thrift是不同语言之间的转换器，是连接不同语言程序间的协议，通过JDBC或者ODBC去访问Hive</li>
<li>HUE客户端：通过Web页面来和Hive进行交互，使用的比较多</li>
</ul>
<h4 id="Hive基本数据类型"><a href="#Hive基本数据类型" class="headerlink" title="Hive基本数据类型"></a>Hive基本数据类型</h4><p>Hive支持关系型数据中大多数基本数据类型，同时Hive中也有特有的三种复杂类型。</p>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>长度</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tinyint</td>
<td>1字节的有符号整数</td>
<td>-128~127</td>
</tr>
<tr>
<td>SmallInt</td>
<td>1个字节的有符号整数</td>
<td>-32768~32767</td>
</tr>
<tr>
<td>Int</td>
<td>4个字节的有符号整数</td>
<td>-2147483648 ~ 2147483647</td>
</tr>
<tr>
<td>BigInt</td>
<td>8个字节的有符号整数</td>
<td></td>
</tr>
<tr>
<td>Boolean</td>
<td>布尔类型，true或者false</td>
<td>true、false</td>
</tr>
<tr>
<td>Float</td>
<td>单精度浮点数</td>
<td></td>
</tr>
<tr>
<td>Double</td>
<td>双精度浮点数</td>
<td></td>
</tr>
<tr>
<td>String</td>
<td>字符串</td>
<td></td>
</tr>
<tr>
<td>TimeStamp</td>
<td>整数    支持Unix timestamp，可以达到纳秒精度</td>
<td></td>
</tr>
<tr>
<td>Binary</td>
<td>字节数组</td>
<td></td>
</tr>
<tr>
<td>Date</td>
<td>日期    0000-01-01 ~ 9999-12-31，常用String代替</td>
</tr>
</tbody>
</table>
<h3 id="DDL操作-库和表的定义"><a href="#DDL操作-库和表的定义" class="headerlink" title="DDL操作(库和表的定义)"></a>DDL操作(库和表的定义)</h3><h4 id="库操作"><a href="#库操作" class="headerlink" title="库操作"></a>库操作</h4><p>创建一个数据库会在HDFS上创建一个目录，Hive里数据库的概念类似于程序中的命名空间，用数据库来组织表，在大量Hive的情况下，用数据库来分开可以避免表名冲突。Hive默认的数据库是default。</p>
<blockquote>
<p>hive&gt; create database if not exists user_db;</p>
</blockquote>
<p>Describe 命令来查看数据库定义，包括：数据库名称、数据库在HDFS目录、HDFS用户名称。</p>
<blockquote>
<p>hive&gt; describe database user_db;<br> 数据库名称  数据库在HDFS的目录  HDFS用户名称</p>
</blockquote>
<p> 删除、切换数据库与mysql命令一样(drop、use)</p>
<h4 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h4><p> 创建表一般有几种方式：</p>
<ul>
<li>create table 方式</li>
<li>create table as select 方式：根据查询的结果自动创建表，并将查询结果数据插入新建的表中</li>
<li><p>create table like tablename1 方式：是克隆表，只复制tablename1表的结构</p>
<h5 id="外部表"><a href="#外部表" class="headerlink" title="外部表"></a>外部表</h5><p>外部表是没有被hive完全控制的表，当表删除后，数据不会被删除。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; create external table iislog_ext (</span><br><span class="line">    &gt;  ip string,</span><br><span class="line">    &gt;  logtime string    </span><br><span class="line">    &gt; )</span><br><span class="line">    &gt; ;</span><br></pre></td></tr></table></figure>
<h5 id="创建分区表"><a href="#创建分区表" class="headerlink" title="创建分区表"></a>创建分区表</h5><p>Hive查询一般是扫描整个目录，但是有时候我们关心的数据只是集中在某一部分数据上，比如我们一个Hive查询，往往是只是查询某一天的数据，这样的情况下，可以使用分区表来优化，一天是一个分区，查询时候，Hive只扫描指定天分区的数据</p>
<p>普通表和分区表的区别在于：一个Hive表在HDFS上是有一个对应的目录来存储数据，普通表的数据直接存储在这个目录下，而分区表数据存储时，是再划分子目录来存储的。一个分区一个子目录。主要作用是来优化查询性能。</p>
<p>例如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">--创建经销商操作日志表</span><br><span class="line">create table user_action_log</span><br><span class="line">(</span><br><span class="line">companyId INT comment   &apos;公司ID&apos;,</span><br><span class="line">userid INT comment   &apos;销售ID&apos;,</span><br><span class="line">originalstring STRING comment   &apos;url&apos;, </span><br><span class="line">host STRING comment   &apos;host&apos;,</span><br><span class="line">absolutepath STRING comment   &apos;绝对路径&apos;,</span><br><span class="line">query STRING comment   &apos;参数串&apos;,</span><br><span class="line">refurl STRING comment   &apos;来源url&apos;,</span><br><span class="line">clientip STRING comment   &apos;客户端Ip&apos;,</span><br><span class="line">cookiemd5 STRING comment   &apos;cookiemd5&apos;,</span><br><span class="line">timestamp STRING comment   &apos;访问时间戳&apos;</span><br><span class="line">)</span><br><span class="line">partitioned by (dt string)</span><br><span class="line">row format delimited fields terminated by &apos;,&apos;</span><br><span class="line">stored as textfile;</span><br></pre></td></tr></table></figure></p>
<p>这个日志表以dt字段分区，dt是个虚拟的字段，dt下并不存储数据，而是用来分区的，实际数据存储时，dt字段值相同的数据存入同一个子目录中，插入数据或者导入数据时，同一天的数据dt字段赋值一样，这样就实现了数据按dt日期分区存储。</p>
<p>当Hive查询数据时，如果指定了dt筛选条件，那么只需要到对应的分区下去检索数据即可，大大提高了效率。所以对于分区表查询时，尽量添加上分区字段的筛选条件</p>
<h5 id="创建桶表"><a href="#创建桶表" class="headerlink" title="创建桶表"></a>创建桶表</h5><p>桶表也是一种用于优化查询而设计的表类型。创建通表时，指定桶的个数、分桶的依据字段，hive就可以自动将数据分桶存储。查询时只需要遍历一个桶里的数据，或者遍历部分桶，这样就提高了查询效率。</p>
<p>例如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">------创建订单表</span><br><span class="line">create table user_leads</span><br><span class="line">(</span><br><span class="line">leads_id string,</span><br><span class="line">user_id string,</span><br><span class="line">user_id string,</span><br><span class="line">user_phone string,</span><br><span class="line">user_name string,</span><br><span class="line">create_time string</span><br><span class="line">)</span><br><span class="line">clustered by (user_id) sorted by(leads_id) into 10 buckets </span><br><span class="line">row format delimited fields terminated by &apos;\t&apos; </span><br><span class="line">stored as textfile;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>clustered by是指根据userid的值进行哈希后模除分桶个数，根据得到的结果，确定这行数据分入哪个桶中，这样的分法，可以确保相同userid的数据放入同一个桶中。而经销商的订单数据，大部分是根据user_id进行查询的。这样大部分情况下是只需要查询一个桶中的数据就可以了</li>
<li>sorted by 是指定桶中的数据以哪个字段进行排序，排序的好处是，在join操作时能获得很高的效率</li>
<li>into 10 buckets是指定一共分10个桶</li>
<li>在HDFS上存储时，一个桶存入一个文件中，这样根据user_id进行查询时，可以快速确定数据存在于哪个桶中，而只遍历一个桶可以提供查询效率</li>
</ul>
<p>分桶表读写过程如下:<br><img src="/images/bigdata/hive-buckets.jpg" alt=""></p>
<h5 id="其他表操作"><a href="#其他表操作" class="headerlink" title="其他表操作"></a>其他表操作</h5><ul>
<li><p>查看表定义:<code>describe userinfo;</code></p>
</li>
<li><p>查看表的详细信息:<code>describe formatted userinfo;</code></p>
</li>
<li><p>修改表名:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">describe formatted userinfo;</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加字段：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">---在user_info表添加一个字段provinceid，int 类型</span><br><span class="line">alter table user_info add columns (provinceid int );</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改字段：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table user_info replace columns (userid int,username string,cityid int,joindate date,provinceid int);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>修改字段，只是修改了Hive表的元数据信息（元数据信息一般是存储在MySql中），并不对存在于HDFS中的表数据做修改。并不是所有的Hive表都可以修改字段，只有使用了native SerDe (序列化反序列化类型)的表才能修改字段</p>
<ul>
<li>删除表:<code>drop table if exists user_info;</code></li>
</ul>
<h3 id="DML操作-数据操作"><a href="#DML操作-数据操作" class="headerlink" title="DML操作(数据操作)"></a>DML操作(数据操作)</h3><h4 id="加载数据到Hive"><a href="#加载数据到Hive" class="headerlink" title="加载数据到Hive"></a>加载数据到Hive</h4><h5 id="加载到普通表"><a href="#加载到普通表" class="headerlink" title="加载到普通表"></a>加载到普通表</h5><p>可以将本地文本文件内容批量加载到Hive表中，要求文本文件中的格式和Hive表的定义一致，包括：字段个数、字段顺序、列分隔符都要一致。</p>
<p>例如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &apos;/home/hadoop/userinfodata.txt&apos; overwrite into table user_info;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>local关键字表示源数据文件在本地，源文件可以在HDFS上，如果在HDFS上，则去掉local，inpath后面的路径是类似”hdfs://namenode:9000/user/datapath”这样的HDFS上文件的路径。</li>
<li>overwrite关键字表示如果hive表中存在数据，就会覆盖掉原有的数据。如果省略overwrite，则默认是追加数据\</li>
</ul>
<h5 id="加载到分区表"><a href="#加载到分区表" class="headerlink" title="加载到分区表"></a>加载到分区表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &apos;/home/hadoop/actionlog.txt&apos; overwrite into table user_action_log </span><br><span class="line">PARTITION (dt=&apos;2017-05-26&apos;);</span><br></pre></td></tr></table></figure>
<p>将这批数据加载到dt为2017-05-26的分区中</p>
<h5 id="加载到分桶表"><a href="#加载到分桶表" class="headerlink" title="加载到分桶表"></a>加载到分桶表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">------先创建普通临时表</span><br><span class="line">create table user_leads_tmp</span><br><span class="line">(</span><br><span class="line">leads_id string,</span><br><span class="line">user_id string,</span><br><span class="line">user_id string,</span><br><span class="line">user_phone string,</span><br><span class="line">user_name string,</span><br><span class="line">create_time string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &apos;,&apos; </span><br><span class="line">stored as textfile;</span><br><span class="line">------数据载入临时表</span><br><span class="line">load data local inpath &apos;/home/hadoop/lead.txt&apos; overwrite into table user_leads_tmp;</span><br><span class="line">------导入分桶表</span><br><span class="line">set hive.enforce.bucketing = true;</span><br><span class="line">insert overwrite table user_leads select * from  user_leads_tmp;</span><br></pre></td></tr></table></figure>
<p><code>set hive.enforce.bucketing = true;</code>表明了启用分桶表</p>
<h4 id="导出数据"><a href="#导出数据" class="headerlink" title="导出数据"></a>导出数据</h4><p>将hive数据导出到本地文件(也可导出到HDFS，将local关键字去掉即可)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite local directory &apos;/home/hadoop/user_info.bak2016-08-22 &apos;</span><br><span class="line">select * from user_info;</span><br></pre></td></tr></table></figure></p>
<h4 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h4><h5 id="insert-select导入"><a href="#insert-select导入" class="headerlink" title="insert select导入"></a>insert select导入</h5><p>这里是将查询结果导入到表中，overwrite关键字是覆盖目标表中的原来数据。如果缺省，就是追加数据:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table user_leads select * from  user_leads_tmp;</span><br></pre></td></tr></table></figure></p>
<p>如果插入数据的表是分区表，则需要加入dt<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table user_leads PARTITION (dt=&apos;2017-05-26&apos;) </span><br><span class="line">select * from  user_leads_tmp;</span><br></pre></td></tr></table></figure></p>
<p>hive每次查询都会将结果集遍历一遍，也可以将一个结果集插入多个表，提高效率:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from user_action_log</span><br><span class="line">insert overwrite table log1 select companyid,originalstring  where companyid=&apos;100006&apos;</span><br><span class="line">insert overwrite table log2 select companyid,originalstring  where companyid=&apos;10002&apos;</span><br></pre></td></tr></table></figure></p>
<h5 id="复制表"><a href="#复制表" class="headerlink" title="复制表"></a>复制表</h5><p>复制表是将源表的结构和数据复制并创建为一个新表，复制过程中，可以对数据进行筛选，列可以进行删减。</p>
<p>对user_leads表进行复制备份，复制时筛选了2016-08-22以前的数据，减少几个列，并添加了一个bakdate列:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table user_leads_bak</span><br><span class="line">row format delimited fields terminated by &apos;\t&apos;</span><br><span class="line">stored as textfile</span><br><span class="line">as</span><br><span class="line">select leads_id,user_id,&apos;2016-08-22&apos; as bakdate</span><br><span class="line">from user_leads</span><br><span class="line">where create_time&lt;&apos;2016-08-22&apos;;</span><br></pre></td></tr></table></figure></p>
<h5 id="克隆表"><a href="#克隆表" class="headerlink" title="克隆表"></a>克隆表</h5><p>克隆表时会克隆源表的所有元数据信息，但是不会复制源表的数据:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--克隆表user_leads，创建新表user_leads_like</span><br><span class="line">create table user_leads_like like  user_leads;</span><br></pre></td></tr></table></figure></p>
<h5 id="备份表"><a href="#备份表" class="headerlink" title="备份表"></a>备份表</h5><p>备份是将表的元数据和数据都导出到HDFS上:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export table user_action_log partition (dt=&apos;2016-08-19&apos;)</span><br><span class="line">to &apos;/user/hive/action_log.export&apos;</span><br></pre></td></tr></table></figure></p>
<h3 id="HQL语句"><a href="#HQL语句" class="headerlink" title="HQL语句"></a>HQL语句</h3><h4 id="select查询"><a href="#select查询" class="headerlink" title="select查询"></a>select查询</h4><ul>
<li><p>指定列</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select * from user_leads;</span><br><span class="line"></span><br><span class="line">select leads_id,user_id,create_time from user_leads;</span><br><span class="line">select e.leads_id from user_leads e;</span><br></pre></td></tr></table></figure>
</li>
<li><p>函数列, 函数可以是hive自带，也可以是用户自定位的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select companyid,upper(host),UUID(32) from user_action_log;</span><br></pre></td></tr></table></figure>
</li>
<li><p>算数运算列，可以进行各种算数运算(加减乘除取模等)，运算结果做为结果列:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select companyid,userid, (companyid + userid) as sumint from useractionlog;</span><br></pre></td></tr></table></figure>
</li>
<li><p>限制返回条数, 与mysql limit类似:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from user_action_log limit 100;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Case When Then 条件判断语句:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">---case when 两种写法</span><br><span class="line">select case companyid when 0 then &apos;未登录&apos; else companyid end from user_action_log;</span><br><span class="line"></span><br><span class="line">select case  when companyid=0 then &apos;未登录&apos; else companyid end from user_action_log;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="where筛选"><a href="#where筛选" class="headerlink" title="where筛选"></a>where筛选</h4><p>支持：=,&lt;,&gt;,&lt;&gt;(不等于),between and等于mysql类似。</p>
<p>还支持匹配操作，如Link, RLike</p>
<h4 id="group-by-分组"><a href="#group-by-分组" class="headerlink" title="group by 分组"></a>group by 分组</h4><p>Hive不支持having语句，有对group by 后的结果进行筛选的需求，可以先将筛选条件放入group by的结果中，然后在包一层，在外边对条件进行筛选。</p>
<p>如mysql中类似<code>SELECT col1 FROM t1 GROUP BY col1 HAVING SUM(col2) &gt; 10</code>,转换为hive中:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT col1 FROM </span><br><span class="line">(SELECT col1, SUM(col2) AS col2sum</span><br><span class="line">       FROM t1 GROUP BY col1</span><br><span class="line">) t2</span><br><span class="line">WHERE t2.col2sum &gt; 10</span><br></pre></td></tr></table></figure></p>
<h4 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h4><p>Hive对子查询的支持有限，只允许在 select from 后面出现。比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">---只支持如下形式的子查询</span><br><span class="line">select * from (</span><br><span class="line">  select userid,username from user_info i where i.userid=&apos;10595&apos;</span><br><span class="line">  ) a;</span><br></pre></td></tr></table></figure></p>
<p>并不支持列名中的子查询，如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">---不支持如下的子查询</span><br><span class="line">select </span><br><span class="line">(select username from user_info i where i.userid=d.user_id) </span><br><span class="line">from user_leads d where d.user_id=&apos;10595&apos;;</span><br></pre></td></tr></table></figure></p>
<h4 id="Join查询"><a href="#Join查询" class="headerlink" title="Join查询"></a>Join查询</h4><p>Hive对Join有一些限制，只支持等值连接，并不支持不等连接。原因是Hive语句最终是要转换为MapReduce程序来执行的，但是MapReduce程序很难实现这种不等判断的连接方式。如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">----等值连接</span><br><span class="line">select lead.* from user_leads lead</span><br><span class="line">left join user_info info </span><br><span class="line">on lead.user_id=info.userid;</span><br><span class="line">---不等连接（不支持）</span><br><span class="line">select lead.* from user_leads lead</span><br><span class="line">left join user_info info </span><br><span class="line">on lead.user_id!=info.userid;</span><br></pre></td></tr></table></figure></p>
<p>并且hive的连接谓词不支持or<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">---on 后面的表达式不支持or</span><br><span class="line">select lead.* from user_leads lead</span><br><span class="line">left join user_info info </span><br><span class="line">on lead.user_id=info.userid or lead.leads_id=0;</span><br></pre></td></tr></table></figure></p>
<h5 id="Inner-Join"><a href="#Inner-Join" class="headerlink" title="Inner Join"></a>Inner Join</h5><p>内连接同Mysql中的一样，连接的两个表中，只有同时满足连接条件的记录才会放入结果表中。</p>
<h5 id="Left-join"><a href="#Left-join" class="headerlink" title="Left join"></a>Left join</h5><p>同MySQL中一样，两个表左连接时，符合Where条件的左侧表的记录都会被保留下来，而符合On条件的右侧的表的记录才会被保留下来。</p>
<h5 id="Right-join"><a href="#Right-join" class="headerlink" title="Right join"></a>Right join</h5><p>同Left Join相反，两个表左连接时，符合Where条件的右侧表的记录都会被保留下来，而符合On条件的左侧的表的记录才会被保留下来。</p>
<h5 id="Full-join"><a href="#Full-join" class="headerlink" title="Full join"></a>Full join</h5><p>Full Join会将连接的两个表中的记录都保留下来。</p>
<h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><h5 id="Order-By"><a href="#Order-By" class="headerlink" title="Order By"></a>Order By</h5><p>order by 的使用与mysql一样，对查询结果进行全局排序，但是Hive语句会放在Hadoop集群中进行MapReduce，如果数据集过大Reduce的过程就会很长，所以尽量不要在Hive中使用order by</p>
<h5 id="Sort-By-和-Distribute-By"><a href="#Sort-By-和-Distribute-By" class="headerlink" title="Sort By 和 Distribute By"></a>Sort By 和 Distribute By</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from user_leads sort by user_id</span><br></pre></td></tr></table></figure>
<p>Sort By是在每个reduce中进行排序，是一个局部排序，可以保证每个Reduce中是按照userid进行排好序的，但是全局上来说，相同的userid可以被分配到不同的Reduce上，虽然在各个Reduce上是排好序的，但是全局上不一定是排好序的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--Distribute By 和Sort By实例</span><br><span class="line">select * from user_leads where user_id!=&apos;0&apos; </span><br><span class="line">Distribute By cast(user_id as int) Sort by cast(user_id as int);</span><br></pre></td></tr></table></figure>
<p>Distribute By 指定map输出结果怎么样划分后分配到各个Reduce上去，比如Distribute By userid，就可以保证userid字段相同的结果被分配到同一个reduce上去执行。然后再指定Sort By userid，则在Reduce上进行按照userid进行排序。</p>
<p>但是这种还是不能做到全局排序，只能保证排序字段值相同的放在一起，并且在reduce上局部是排好序的。</p>
<p>需要注意的是Distribute By 必须写在Sort By前面。</p>
<h5 id="Cluster-By"><a href="#Cluster-By" class="headerlink" title="Cluster By"></a>Cluster By</h5><p>如果Distribute By和Sort By的字段是同一个，可以简写为 Cluster By.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from user_leads where user_id!=&apos;0&apos; </span><br><span class="line">Cluster By cast(user_id as int) ;</span><br></pre></td></tr></table></figure></p>
<h5 id="最终结果有序"><a href="#最终结果有序" class="headerlink" title="最终结果有序"></a>最终结果有序</h5><p>最终结果是比较大的，一般是取得一个小的结果集，然后在小的结果集上进行order by排序:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select * from (</span><br><span class="line">select user_id,count(leads_id) cnt from user_leads  </span><br><span class="line">where user_id!=&apos;0&apos; </span><br><span class="line">group by user_id</span><br><span class="line">) a order by a.cnt;</span><br></pre></td></tr></table></figure></p>
<p>先用group by获得一个小的结果集，在对晓得结果集进行order by排序</p>
<h5 id="取前N条有序"><a href="#取前N条有序" class="headerlink" title="取前N条有序"></a>取前N条有序</h5><p>按某个字段排序后，取出前N条:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select a.leads_id,a.user_name from (</span><br><span class="line">  select leads_id,user_name  from user_leads  </span><br><span class="line">distribute by length(user_name)  sort by length(user_name) desc limit 10</span><br><span class="line"> ) a order by length(a.user_name) desc limit 10;</span><br></pre></td></tr></table></figure></p>
<p>这个语句是查询username最长的10条记录，实现是先根据username的长度在各个Reduce上进行排序后取各自的前10个，然后再从10*N条的结果集里用order by取前10个。</p>
<h3 id="MapReduce执行过程"><a href="#MapReduce执行过程" class="headerlink" title="MapReduce执行过程"></a>MapReduce执行过程</h3><p>Hive语句最终是要转换为MapReduce程序放到Hadoop上去执行的。</p>
<h4 id="MapReduce执行过程简介"><a href="#MapReduce执行过程简介" class="headerlink" title="MapReduce执行过程简介"></a>MapReduce执行过程简介</h4><p>MapReduce过程大体分为两个阶段：map函数阶段和reduce函数阶段，两个阶段之间有有个shuffle。</p>
<p><img src="/images/bigdata/mapreduce-principle.jpg" alt=""></p>
<ul>
<li>Hadoop将MapReduce输入的数据划分为等长的小分片，一般每个分片是128M，因为HDFS的每个块是128M</li>
<li>map函数是数据准备阶段，读取分片内容，并筛选掉不需要的数据，将数据解析为键值对的形式输出，map函数核心目的是形成对数据的索引，以供reduce函数方便对数据进行分析</li>
<li>在map函数执行完后，进行map端的shuffle过程，map端的shuffle是将map函数的输出进行分区，不同分区的数据要传入不同的Reduce里去</li>
<li>各个分区里的数据传入Reduce后，会先进行Reduce端的Shuffle过程，这里会将各个Map传递过来的相同分区的进行排序，然后进行分组，一个分组的数据执行一次reduce函数</li>
<li>reduce函数以分组的数据为数据源，对数据进行相应的分析，输出结果为最终的目标数据</li>
<li>由于map任务的输出结果传递给reduce任务过程中，是在节点间的传输，是占用带宽的，这样带宽就制约了程序执行过程的最大吞吐量，为了减少map和reduce间的数据传输，在map后面添加了combiner函数来就map结果进行预处理，combiner函数是运行在map所在节点的</li>
</ul>
<p>执行过程图如:<br><img src="/images/bigdata/mapreduce.jpg" alt=""></p>
<h4 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h4><p>HDFS上的文件要用很多mapper进程处理，而map函数接收的输入是键值对的形式，所以要先将文件进行切分并组织成键值对的形式，这个切分和转换的过程就是数据分片。</p>
<h4 id="Map过程"><a href="#Map过程" class="headerlink" title="Map过程"></a>Map过程</h4><p>每个数据分片将启动一个Map进程来处理，分片里的每个键值对运行一次map函数，根据map函数里定义的业务逻辑处理后，得到指定类型的键值对。</p>
<h4 id="Map-shuffle过程"><a href="#Map-shuffle过程" class="headerlink" title="Map shuffle过程"></a>Map shuffle过程</h4><p>Map端的shuffle如下:<br><img src="/images/bigdata/map-shuffle.jpg" alt=""></p>
<h5 id="环形缓冲区"><a href="#环形缓冲区" class="headerlink" title="环形缓冲区"></a>环形缓冲区</h5><p>Map输出结果是先放入内存中的一个环形缓冲区，这个环形缓冲区默认大小为100M(这个大小可以在<code>io.sort.mb</code>属性中设置)，当环形缓冲区里的数据量达到阀值时（这个值可以在<code>io.sort.spill.percent</code>属性中设置）就会溢出写入到磁盘，环形缓冲区是遵循先进先出原则，Map输出一直不停地写入，一个后台进程不时地读取后写入磁盘，如果写入速度快于读取速度导致环形缓冲区里满了时，map输出会被阻塞直到写磁盘过程结束。</p>
<h5 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h5><p>从环形缓冲区溢出到磁盘过程，是将数据写入<code>mapred.local.dir</code>属性指定目录下的特定子目录的过程。 但是在真正写入磁盘之前，要进行一系列的操作，首先就是对于每个键，根据规则计算出来将来要输出到哪个reduce，根据reduce不同分不同的区，分区是在内存里分的，分区的个数和将来的reduce个数是一致的</p>
<h5 id="排序-1"><a href="#排序-1" class="headerlink" title="排序"></a>排序</h5><p>在每个分区上会根据键进行排序</p>
<h5 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h5><p>combiner方法是对于map输出的结果按照业务逻辑预先进行处理，目的是对数据进行合并，减少map输出的数据量。</p>
<p>排序后，如果指定了conmbiner方法，就运行combiner方法使得map的结果更紧凑，从而减少写入磁盘和将来网络传输的数据量</p>
<h5 id="合并溢出文件"><a href="#合并溢出文件" class="headerlink" title="合并溢出文件"></a>合并溢出文件</h5><p>环形缓冲区每次溢出，都会生成一个文件，所以在map任务全部完成之前，会进行合并成为一个溢出文件，每次溢出的各个文件都是按照分区进行排好序的，所以在合并文件过程中，也要进行分区和排序，最终形成一个已经分区和排好序的map输出文件。</p>
<p>在合并文件时，如果文件个数大于某个指定的数量（可以在<code>min.num.spills.for.combine</code>属性设置），就会进再次combiner操作，如果文件太少，效果和效率上，就不值得花时间再去执行combiner来减少数据量了</p>
<h5 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h5><p>Map输出结果在进行了一系列的分区、排序、combiner合并、合并溢出文件后，得到一个map最终的结果后，就应该真正存储这个结果了，在存储之前，可以对最终结果数据进行压缩，一是可以节约磁盘空间，而是可以减少传递给reduce时的网络传输数据量。</p>
<p>默认是不进行压缩的，可以在<code>mapred.compress.map.output</code>属性设置为true就启用了压缩，而压缩的算法有很多，可以在<code>mapred.map.output.compression.codec</code>属性中指定采用的压缩算法</p>
<h4 id="Reduce-Shuffle过程"><a href="#Reduce-Shuffle过程" class="headerlink" title="Reduce Shuffle过程"></a>Reduce Shuffle过程</h4><p>Map端Shuffle完成后，将处理结果存入磁盘，然后通过网络传输到Reduce节点上，Reduce端首先对各个Map传递过来的数据进行Reduce 端的Shuffle操作，Reduce端的Shuffle过程如下所示：</p>
<p><img src="/images/bigdata/reduce-shuffle.jpg" alt=""></p>
<h5 id="复制数据"><a href="#复制数据" class="headerlink" title="复制数据"></a>复制数据</h5><p>各个map完成时间肯定是不同的，只要有一个map执行完成，reduce就开始去从已完成的map节点上复制输出文件中属于它的分区中的数据，reduce端是多线程并行来复制各个map节点的输出文件的，线程数可以在<code>mapred.reduce.parallel.copies</code>属性中设置。</p>
<p>reduce将复制来的数据放入内存缓冲区（缓冲区大小可以在<code>mapred.job.shuffle.input.buffer.percent</code>属性中设置）。当内存缓冲区中数据达到阀值大小或者达到map输出阀值，就会溢写到磁盘。</p>
<p>写入磁盘之前，会对各个map节点来的数据进行合并排序，合并时如果指定了combiner，则会再次执行combiner以尽量减少写入磁盘的数据量。为了合并，如果map输出是压缩过的，要在内存中先解压缩后合并</p>
<h5 id="合并数据"><a href="#合并数据" class="headerlink" title="合并数据"></a>合并数据</h5><p>合并排序其实是和复制文件同时并行执行的，最终目的是将来自各个map节点的数据合并并排序后，形成一个文件</p>
<h5 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h5><p>分组是将相同key的键值对分为一组，一组是一个列表，列表中每一组在一次reduce方法中处理</p>
<h5 id="执行reduce方法"><a href="#执行reduce方法" class="headerlink" title="执行reduce方法"></a>执行reduce方法</h5><p>reduce端的shuffle后，就会执行reduce方法</p>
<p>Reduce端的Shuffle过程后，最终形成了分好组的键值对列表，相同键的数据分为一组，分组的键是分组的键，值是原来值得列表，然后每一个分组执行一次reduce函数，根据reduce函数里的业务逻辑处理后，生成指定格式的键值对。</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul>
<li><a href="https://gitbook.cn/books/5924bd0523245b0aa3776b65/index.html" target="_blank" rel="noopener">Hive快速入门</a></li>
<li><a href="https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html" target="_blank" rel="noopener">Hive sql编译过程-美团点评</a></li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hive/" rel="tag"><i class="fa fa-tag"></i> hive</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/01/hdfs介绍/" rel="next" title="hdfs介绍">
                <i class="fa fa-chevron-left"></i> hdfs介绍
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/11/hbase基本使用/" rel="prev" title="hbase基本使用">
                hbase基本使用 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <p class="site-author-name" itemprop="name">Leo Hao</p>
            <p class="site-description motion-element" itemprop="description">勿在浮沙筑高台</p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">53</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#hive简介"><span class="nav-number">1.</span> <span class="nav-text">hive简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#整体架构"><span class="nav-number">2.</span> <span class="nav-text">整体架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#驱动引擎"><span class="nav-number">2.1.</span> <span class="nav-text">驱动引擎</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#底层存储和执行流程"><span class="nav-number">2.2.</span> <span class="nav-text">底层存储和执行流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive元数据的存储结构"><span class="nav-number">2.3.</span> <span class="nav-text">Hive元数据的存储结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive客户端"><span class="nav-number">2.4.</span> <span class="nav-text">Hive客户端</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive基本数据类型"><span class="nav-number">2.5.</span> <span class="nav-text">Hive基本数据类型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DDL操作-库和表的定义"><span class="nav-number">3.</span> <span class="nav-text">DDL操作(库和表的定义)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#库操作"><span class="nav-number">3.1.</span> <span class="nav-text">库操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建表"><span class="nav-number">3.2.</span> <span class="nav-text">创建表</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#外部表"><span class="nav-number">3.2.1.</span> <span class="nav-text">外部表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#创建分区表"><span class="nav-number">3.2.2.</span> <span class="nav-text">创建分区表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#创建桶表"><span class="nav-number">3.2.3.</span> <span class="nav-text">创建桶表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#其他表操作"><span class="nav-number">3.2.4.</span> <span class="nav-text">其他表操作</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DML操作-数据操作"><span class="nav-number">4.</span> <span class="nav-text">DML操作(数据操作)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#加载数据到Hive"><span class="nav-number">4.1.</span> <span class="nav-text">加载数据到Hive</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#加载到普通表"><span class="nav-number">4.1.1.</span> <span class="nav-text">加载到普通表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#加载到分区表"><span class="nav-number">4.1.2.</span> <span class="nav-text">加载到分区表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#加载到分桶表"><span class="nav-number">4.1.3.</span> <span class="nav-text">加载到分桶表</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#导出数据"><span class="nav-number">4.2.</span> <span class="nav-text">导出数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#插入数据"><span class="nav-number">4.3.</span> <span class="nav-text">插入数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#insert-select导入"><span class="nav-number">4.3.1.</span> <span class="nav-text">insert select导入</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#复制表"><span class="nav-number">4.3.2.</span> <span class="nav-text">复制表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#克隆表"><span class="nav-number">4.3.3.</span> <span class="nav-text">克隆表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#备份表"><span class="nav-number">4.3.4.</span> <span class="nav-text">备份表</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HQL语句"><span class="nav-number">5.</span> <span class="nav-text">HQL语句</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#select查询"><span class="nav-number">5.1.</span> <span class="nav-text">select查询</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#where筛选"><span class="nav-number">5.2.</span> <span class="nav-text">where筛选</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#group-by-分组"><span class="nav-number">5.3.</span> <span class="nav-text">group by 分组</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#子查询"><span class="nav-number">5.4.</span> <span class="nav-text">子查询</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Join查询"><span class="nav-number">5.5.</span> <span class="nav-text">Join查询</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Inner-Join"><span class="nav-number">5.5.1.</span> <span class="nav-text">Inner Join</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Left-join"><span class="nav-number">5.5.2.</span> <span class="nav-text">Left join</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Right-join"><span class="nav-number">5.5.3.</span> <span class="nav-text">Right join</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Full-join"><span class="nav-number">5.5.4.</span> <span class="nav-text">Full join</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#排序"><span class="nav-number">5.6.</span> <span class="nav-text">排序</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Order-By"><span class="nav-number">5.6.1.</span> <span class="nav-text">Order By</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Sort-By-和-Distribute-By"><span class="nav-number">5.6.2.</span> <span class="nav-text">Sort By 和 Distribute By</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Cluster-By"><span class="nav-number">5.6.3.</span> <span class="nav-text">Cluster By</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#最终结果有序"><span class="nav-number">5.6.4.</span> <span class="nav-text">最终结果有序</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#取前N条有序"><span class="nav-number">5.6.5.</span> <span class="nav-text">取前N条有序</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce执行过程"><span class="nav-number">6.</span> <span class="nav-text">MapReduce执行过程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce执行过程简介"><span class="nav-number">6.1.</span> <span class="nav-text">MapReduce执行过程简介</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分片"><span class="nav-number">6.2.</span> <span class="nav-text">分片</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Map过程"><span class="nav-number">6.3.</span> <span class="nav-text">Map过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Map-shuffle过程"><span class="nav-number">6.4.</span> <span class="nav-text">Map shuffle过程</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#环形缓冲区"><span class="nav-number">6.4.1.</span> <span class="nav-text">环形缓冲区</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#分区"><span class="nav-number">6.4.2.</span> <span class="nav-text">分区</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#排序-1"><span class="nav-number">6.4.3.</span> <span class="nav-text">排序</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Combiner"><span class="nav-number">6.4.4.</span> <span class="nav-text">Combiner</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#合并溢出文件"><span class="nav-number">6.4.5.</span> <span class="nav-text">合并溢出文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#压缩"><span class="nav-number">6.4.6.</span> <span class="nav-text">压缩</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reduce-Shuffle过程"><span class="nav-number">6.5.</span> <span class="nav-text">Reduce Shuffle过程</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#复制数据"><span class="nav-number">6.5.1.</span> <span class="nav-text">复制数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#合并数据"><span class="nav-number">6.5.2.</span> <span class="nav-text">合并数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#分组"><span class="nav-number">6.5.3.</span> <span class="nav-text">分组</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#执行reduce方法"><span class="nav-number">6.5.4.</span> <span class="nav-text">执行reduce方法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参考资料"><span class="nav-number">7.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leo Hao</span>

  
</div>

  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.2</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  

  

  

  

  

</body>
</html>
